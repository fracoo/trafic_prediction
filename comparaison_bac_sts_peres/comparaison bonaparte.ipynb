{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fabdd74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "peres = pd.read_csv('./dataset_brut/sts_peres.csv', sep=\";\")\n",
    "bonaparte = pd.read_csv('./dataset_brut/bonaparte.csv', sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ab8b4e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Identifiant arc               0.000000\n",
       "Libelle                       0.000000\n",
       "Date et heure de comptage     0.000000\n",
       "Débit horaire                79.289877\n",
       "Taux d'occupation            79.289877\n",
       "Etat trafic                   0.000000\n",
       "Identifiant noeud amont       0.000000\n",
       "Libelle noeud amont           0.000000\n",
       "Identifiant noeud aval        0.000000\n",
       "Libelle noeud aval            0.000000\n",
       "Etat arc                      0.000000\n",
       "Date debut dispo data         0.000000\n",
       "Date fin dispo data           0.000000\n",
       "geo_point_2d                  0.000000\n",
       "geo_shape                     0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(peres.isnull().sum()/peres.shape[0])*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac352277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Identifiant arc                0.000000\n",
       "Libelle                        0.000000\n",
       "Date et heure de comptage      0.000000\n",
       "Débit horaire                  1.910209\n",
       "Taux d'occupation            100.000000\n",
       "Etat trafic                    0.000000\n",
       "Identifiant noeud amont        0.000000\n",
       "Libelle noeud amont            0.000000\n",
       "Identifiant noeud aval         0.000000\n",
       "Libelle noeud aval             0.000000\n",
       "Etat arc                       0.000000\n",
       "Date debut dispo data          0.000000\n",
       "Date fin dispo data            0.000000\n",
       "geo_point_2d                   0.000000\n",
       "geo_shape                      0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(bonaparte.isnull().sum()/bonaparte.shape[0])*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afd6f8e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9266\n"
     ]
    }
   ],
   "source": [
    "bonaparte['Date et heure de comptage'] = pd.to_datetime(\n",
    "    bonaparte['Date et heure de comptage'],\n",
    "    errors='coerce',\n",
    "    utc=True\n",
    ").dt.tz_convert('Europe/Paris').dt.tz_localize(None)\n",
    "print(len(bonaparte['Date et heure de comptage'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7617fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9266\n"
     ]
    }
   ],
   "source": [
    "peres['Date et heure de comptage'] = pd.to_datetime(\n",
    "    peres['Date et heure de comptage'],\n",
    "    errors='coerce',\n",
    "    utc=True\n",
    ").dt.tz_convert('Europe/Paris').dt.tz_localize(None)\n",
    "print(len(peres['Date et heure de comptage'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2fd6318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Identifiant arc_x', 'Libelle_x', 'Date et heure de comptage', 'Débit horaire_x', \"Taux d'occupation_x\", 'Etat trafic_x', 'Identifiant noeud amont_x', 'Libelle noeud amont_x', 'Identifiant noeud aval_x', 'Libelle noeud aval_x', 'Etat arc_x', 'Date debut dispo data_x', 'Date fin dispo data_x', 'geo_point_2d_x', 'geo_shape_x', 'Identifiant arc_y', 'Libelle_y', 'Débit horaire_y', \"Taux d'occupation_y\", 'Etat trafic_y', 'Identifiant noeud amont_y', 'Libelle noeud amont_y', 'Identifiant noeud aval_y', 'Libelle noeud aval_y', 'Etat arc_y', 'Date debut dispo data_y', 'Date fin dispo data_y', 'geo_point_2d_y', 'geo_shape_y']\n"
     ]
    }
   ],
   "source": [
    "bonaparte = bonaparte.sort_values('Date et heure de comptage')\n",
    "peres = peres.sort_values('Date et heure de comptage')\n",
    "\n",
    "df_merge = pd.merge(bonaparte,peres, on='Date et heure de comptage', how = \"inner\")\n",
    "\n",
    "df_merge.to_csv(\"./mrged.csv\", sep=\";\")\n",
    "print(df_merge.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "165a7b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Pas assez de paires valides après nettoyage (n < 2).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 29\u001b[0m\n\u001b[1;32m     27\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(df_valid)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m---> 29\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPas assez de paires valides après nettoyage (n < 2).\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m df_valid[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTaux d\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moccupation_x\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mnunique() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m df_valid[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTaux d\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moccupation_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mnunique() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mune des séries est constante : la corrélation de Pearson est indéfinie.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Pas assez de paires valides après nettoyage (n < 2)."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Tri (ok)\n",
    "# bac = bac.sort_values('Date et heure de comptage')\n",
    "# peres = peres.sort_values('Date et heure de comptage')\n",
    "\n",
    "# Jointure stricte sur l'horodatage\n",
    "df = df_merge\n",
    "\n",
    "# Nettoyage des deux colonnes (virgules décimales, % éventuel, espaces)\n",
    "for col in [\"Taux d'occupation_x\", \"Taux d'occupation_y\"]:\n",
    "    df[col] = (\n",
    "        df[col]\n",
    "        .astype(str)\n",
    "        .str.replace('%', '', regex=False)\n",
    "        .str.replace(',', '.', regex=False)\n",
    "        .str.strip()\n",
    "    )\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# Ne garder que les lignes où les deux valeurs existent\n",
    "df_valid = df.dropna(subset=[\"Taux d'occupation_x\", \"Taux d'occupation_y\"])\n",
    "print(df_valid.shape[0])\n",
    "\n",
    "# Contrôles de validité\n",
    "n = len(df_valid)\n",
    "if n < 2:\n",
    "    raise ValueError(\"Pas assez de paires valides après nettoyage (n < 2).\")\n",
    "\n",
    "if df_valid[\"Taux d'occupation_x\"].nunique() == 1 or df_valid[\"Taux d'occupation_y\"].nunique() == 1:\n",
    "    raise ValueError(\"L'une des séries est constante : la corrélation de Pearson est indéfinie.\")\n",
    "\n",
    "# Corrélation de Pearson\n",
    "r = df_valid[\"Taux d'occupation_x\"].corr(df_valid[\"Taux d'occupation_y\"])\n",
    "print(\"Corrélation :\", r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbede4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1885\n",
      "0.8932025415739622\n"
     ]
    }
   ],
   "source": [
    "df_valid_debit = df.dropna(subset=[\"Débit horaire_x\", \"Débit horaire_y\"])\n",
    "print(df_valid_debit.shape[0])\n",
    "r = df_valid_debit[\"Débit horaire_x\"].corr(df_valid_debit[\"Débit horaire_y\"])\n",
    "print(r)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
