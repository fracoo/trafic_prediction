{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfb678f6",
   "metadata": {},
   "source": [
    "<h2>Objectifs</h2>\n",
    "\n",
    "Dans ce fichier, nous cherchons à mettre en forme les bases de données relatives aux trois axes dont nous cherchons à estimer le débit de voitures et le taux d'occupation (les champs Élysées, rue de la Convention, et la rue des Saints-Pères). Pour ce faire, nous allons utiliser les données brutes extraites, puis les retraiter afin de faire face aux données manquantes, ajouter des features (comme la météo, des données sur les vacances, des éventuels évènements dans Paris, des perturbations telles que des chantiers sur les axes d'intérêt directement ou sur les axes voisins...). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94eb14f",
   "metadata": {},
   "source": [
    "Imports :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54120c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.api.types import is_datetime64_any_dtype as is_dt\n",
    "from pandas.api.types import is_datetime64tz_dtype as is_dt_tz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473bb17e",
   "metadata": {},
   "source": [
    "Tout d'abord, nous allons déterminer comment se présente les données, c'est à dire le type de chaque colonne, le nombre de données non-nulles pour les variables numériques et les valeurs possibles prises pour les variables catégorielles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23fdfc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9266 entries, 0 to 9265\n",
      "Data columns (total 15 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   Identifiant arc            9266 non-null   int64  \n",
      " 1   Libelle                    9266 non-null   object \n",
      " 2   Date et heure de comptage  9266 non-null   object \n",
      " 3   Débit horaire              8703 non-null   float64\n",
      " 4   Taux d'occupation          8644 non-null   float64\n",
      " 5   Etat trafic                9266 non-null   object \n",
      " 6   Identifiant noeud amont    9266 non-null   int64  \n",
      " 7   Libelle noeud amont        9266 non-null   object \n",
      " 8   Identifiant noeud aval     9266 non-null   int64  \n",
      " 9   Libelle noeud aval         9266 non-null   object \n",
      " 10  Etat arc                   9266 non-null   object \n",
      " 11  Date debut dispo data      9266 non-null   object \n",
      " 12  Date fin dispo data        9266 non-null   object \n",
      " 13  geo_point_2d               9266 non-null   object \n",
      " 14  geo_shape                  9266 non-null   object \n",
      "dtypes: float64(2), int64(3), object(10)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./dataset/champs_elysees.csv', sep=\";\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c580c31",
   "metadata": {},
   "source": [
    "Dans un premier temps, nous allons mettre le champ \"Date et heure de comptage\" dans un format compatible avec nos autres datasets, l'objectif étant plus tard de les fusionner. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade531fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9266\n"
     ]
    }
   ],
   "source": [
    "df['Date et heure de comptage'] = pd.to_datetime(\n",
    "    df['Date et heure de comptage'],\n",
    "    errors='coerce',\n",
    "    utc=True\n",
    ").dt.tz_convert('Europe/Paris').dt.tz_localize(None)\n",
    "print(len(df['Date et heure de comptage'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902b3de3",
   "metadata": {},
   "source": [
    "Maintenant nous pouvons merge ce dataset avec celui donnant des informations sur la météo. On commence par importer le dataset relatif à la météo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5f597a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16036 entries, 0 to 16035\n",
      "Data columns (total 6 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Unnamed: 0                16036 non-null  int64  \n",
      " 1   NOM_USUEL                 16036 non-null  object \n",
      " 2   precipitations heure      16035 non-null  float64\n",
      " 3   duree prec (en min)       15935 non-null  float64\n",
      " 4   force moyenne vent (m/s)  16033 non-null  float64\n",
      " 5   datetime                  16036 non-null  object \n",
      "dtypes: float64(3), int64(1), object(2)\n",
      "memory usage: 751.8+ KB\n"
     ]
    }
   ],
   "source": [
    "meteo = pd.read_csv('./dataset/meteo.csv', sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89a7a6d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You are trying to merge on datetime64[ns] and object columns for key 'Date et heure de comptage'. If you wish to proceed you should use pd.concat",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_ce_n_meteo \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeteo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDate et heure de comptage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdatetime\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mleft\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(df_ce_n_meteo\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/reshape/merge.py:170\u001b[0m, in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _cross_merge(\n\u001b[1;32m    156\u001b[0m         left_df,\n\u001b[1;32m    157\u001b[0m         right_df,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    167\u001b[0m         copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[1;32m    168\u001b[0m     )\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 170\u001b[0m     op \u001b[38;5;241m=\u001b[39m \u001b[43m_MergeOperation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result(copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/reshape/merge.py:807\u001b[0m, in \u001b[0;36m_MergeOperation.__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[1;32m    803\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_tolerance(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_join_keys)\n\u001b[1;32m    805\u001b[0m \u001b[38;5;66;03m# validate the merge keys dtypes. We may need to coerce\u001b[39;00m\n\u001b[1;32m    806\u001b[0m \u001b[38;5;66;03m# to avoid incompatible dtypes\u001b[39;00m\n\u001b[0;32m--> 807\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_coerce_merge_keys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    809\u001b[0m \u001b[38;5;66;03m# If argument passed to validate,\u001b[39;00m\n\u001b[1;32m    810\u001b[0m \u001b[38;5;66;03m# check if columns specified as unique\u001b[39;00m\n\u001b[1;32m    811\u001b[0m \u001b[38;5;66;03m# are in fact unique.\u001b[39;00m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/reshape/merge.py:1512\u001b[0m, in \u001b[0;36m_MergeOperation._maybe_coerce_merge_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;66;03m# datetimelikes must match exactly\u001b[39;00m\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m needs_i8_conversion(lk\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m needs_i8_conversion(rk\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[0;32m-> 1512\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m   1513\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m needs_i8_conversion(lk\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m needs_i8_conversion(rk\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[0;31mValueError\u001b[0m: You are trying to merge on datetime64[ns] and object columns for key 'Date et heure de comptage'. If you wish to proceed you should use pd.concat"
     ]
    }
   ],
   "source": [
    "df_ce_n_meteo = pd.merge(df, meteo, left_on='Date et heure de comptage', right_on='datetime', how='left')\n",
    "print(df_ce_n_meteo.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
